{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1 - Proposta de Modelo de Síntese de Dado Tabular em Saúde\n",
    "\n",
    "#### Aluno: Tiago Amorim (100.675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = pd.read_csv('./data_agg.csv', parse_dates=['Date'])\n",
    "# df_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Sex', 'PLAQUETAS SANGUE', 'NEUTRÓFILOS ABSOLUTO',\n",
       "       'LINFÓCITOS ABSOLUTO', 'NEUTRÓFILOS %', 'LINFÓCITOS %'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df_agg.columns[-7:]\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geração de Amostras com VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseado em: https://hunterheidenreich.com/posts/modern-variational-autoencoder-in-pytorch/\n",
    "\n",
    "@dataclass\n",
    "class VAEOutput:\n",
    "    \"\"\"\n",
    "    Dataclass for VAE output.\n",
    "\n",
    "    Attributes:\n",
    "        z_dist (torch.distributions.Distribution): The distribution of the latent variable z.\n",
    "        z_sample (torch.Tensor): The sampled value of the latent variable z.\n",
    "        x_recon (torch.Tensor): The reconstructed output from the VAE.\n",
    "        loss (torch.Tensor): The overall loss of the VAE.\n",
    "        loss_recon (torch.Tensor): The reconstruction loss component of the VAE loss.\n",
    "        loss_kl (torch.Tensor): The KL divergence component of the VAE loss.\n",
    "    \"\"\"\n",
    "    z_dist: torch.distributions.Distribution\n",
    "    z_sample: torch.Tensor\n",
    "    x_recon: torch.Tensor\n",
    "\n",
    "    loss: torch.Tensor\n",
    "\n",
    "    loss_recon: torch.Tensor\n",
    "    loss_kl: torch.Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational Autoencoder (VAE) class.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Dimensionality of the input data.\n",
    "        hidden_dim (int): Dimensionality of the hidden layer.\n",
    "        latent_dim (int): Dimensionality of the latent space.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim // 2, 2 * latent_dim), # 2 for mean and variance.\n",
    "        )\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim // 2, input_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def encode(self, x, eps: float = 1e-8):\n",
    "        \"\"\"\n",
    "        Encodes the input data into the latent space.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input data.\n",
    "            eps (float): Small value to avoid numerical instability.\n",
    "\n",
    "        Returns:\n",
    "            torch.distributions.MultivariateNormal: Normal distribution of the encoded data.\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)\n",
    "        mu, logvar = torch.chunk(x, 2, dim=-1)\n",
    "        scale = self.softplus(logvar) + eps\n",
    "        scale_tril = torch.diag_embed(scale)\n",
    "\n",
    "        return torch.distributions.MultivariateNormal(mu, scale_tril=scale_tril)\n",
    "\n",
    "    def reparameterize(self, dist):\n",
    "        \"\"\"\n",
    "        Reparameterizes the encoded data to sample from the latent space.\n",
    "\n",
    "        Args:\n",
    "            dist (torch.distributions.MultivariateNormal): Normal distribution of the encoded data.\n",
    "        Returns:\n",
    "            torch.Tensor: Sampled data from the latent space.\n",
    "        \"\"\"\n",
    "        return dist.rsample()\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decodes the data from the latent space to the original input space.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): Data in the latent space.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Reconstructed data in the original input space.\n",
    "        \"\"\"\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x, compute_loss: bool = True):\n",
    "        \"\"\"\n",
    "        Performs a forward pass of the VAE.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input data.\n",
    "            compute_loss (bool): Whether to compute the loss or not.\n",
    "\n",
    "        Returns:\n",
    "            VAEOutput: VAE output dataclass.\n",
    "        \"\"\"\n",
    "        dist = self.encode(x)\n",
    "        z = self.reparameterize(dist)\n",
    "        recon_x = self.decode(z)\n",
    "\n",
    "        if not compute_loss:\n",
    "            return VAEOutput(\n",
    "                z_dist=dist,\n",
    "                z_sample=z,\n",
    "                x_recon=recon_x,\n",
    "                loss=None,\n",
    "                loss_recon=None,\n",
    "                loss_kl=None,\n",
    "            )\n",
    "\n",
    "        # compute loss terms\n",
    "        # loss_recon = F.binary_cross_entropy(recon_x, x + 0.5, reduction='none').sum(-1).mean()\n",
    "        loss_recon = F.mse_loss(recon_x, x, reduction='mean')\n",
    "        std_normal = torch.distributions.MultivariateNormal(\n",
    "            torch.zeros_like(z, device=z.device),\n",
    "            scale_tril=torch.eye(z.shape[-1], device=z.device).unsqueeze(0).expand(z.shape[0], -1, -1),\n",
    "        )\n",
    "        loss_kl = torch.distributions.kl.kl_divergence(dist, std_normal).mean()\n",
    "\n",
    "        loss = loss_recon + loss_kl\n",
    "\n",
    "        return VAEOutput(\n",
    "            z_dist=dist,\n",
    "            z_sample=z,\n",
    "            x_recon=recon_x,\n",
    "            loss=loss,\n",
    "            loss_recon=loss_recon,\n",
    "            loss_kl=loss_kl,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_values = df_agg[columns].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_values)\n",
    "X_train_scaled, X_test_scaled = train_test_split(X_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test_scaled, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    X_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    X_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-2\n",
    "num_epochs = 50\n",
    "latent_dim = 6\n",
    "hidden_dim = 3\n",
    "\n",
    "device = 'cpu' #torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = VAE(input_dim=7, hidden_dim=hidden_dim, latent_dim=latent_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "writer = SummaryWriter(f'runs/vae01/vae_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAEOutput(z_dist=MultivariateNormal(loc: torch.Size([1, 6]), scale_tril: torch.Size([1, 6, 6])), z_sample=tensor([[ 0.7509, -0.3297, -1.1785, -0.0131,  0.2195, -1.1760]],\n",
       "       grad_fn=<AddBackward0>), x_recon=tensor([[0.7090, 0.2971, 0.7039, 0.5713, 0.5397, 0.3027, 0.7055]],\n",
       "       grad_fn=<SigmoidBackward0>), loss=tensor(5.3078, grad_fn=<AddBackward0>), loss_recon=tensor(2.5687, grad_fn=<MseLossBackward0>), loss_kl=tensor(2.7390, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(train_loader.dataset[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 91\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Number of parameters in the model: {count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, prev_updates, writer=None):\n",
    "    \"\"\"\n",
    "    Trains the model on the given data.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        dataloader (torch.utils.data.DataLoader): The data loader.\n",
    "        loss_fn: The loss function.\n",
    "        optimizer: The optimizer.\n",
    "    \"\"\"\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for batch_idx, data in enumerate(tqdm(dataloader)):\n",
    "        n_upd = prev_updates + batch_idx\n",
    "\n",
    "        data = data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        output = model(data)  # Forward pass\n",
    "        loss = output.loss\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if n_upd % 100 == 0:\n",
    "            # Calculate and log gradient norms\n",
    "            total_norm = 0.0\n",
    "            for p in model.parameters():\n",
    "                if p.grad is not None:\n",
    "                    param_norm = p.grad.data.norm(2)\n",
    "                    total_norm += param_norm.item() ** 2\n",
    "            total_norm = total_norm ** (1. / 2)\n",
    "\n",
    "            print(f'Step {n_upd:,} (N samples: {n_upd*batch_size:,}), Loss: {loss.item():.4f} (Recon: {output.loss_recon.item():.4f}, KL: {output.loss_kl.item():.4f}) Grad: {total_norm:.4f}')\n",
    "\n",
    "            if writer is not None:\n",
    "                global_step = n_upd\n",
    "                writer.add_scalar('Loss/Train', loss.item(), global_step)\n",
    "                writer.add_scalar('Loss/Train/BCE', output.loss_recon.item(), global_step)\n",
    "                writer.add_scalar('Loss/Train/KLD', output.loss_kl.item(), global_step)\n",
    "                writer.add_scalar('GradNorm/Train', total_norm, global_step)\n",
    "\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()  # Update the model parameters\n",
    "\n",
    "    return prev_updates + len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, cur_step, writer=None):\n",
    "    \"\"\"\n",
    "    Tests the model on the given data.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to test.\n",
    "        dataloader (torch.utils.data.DataLoader): The data loader.\n",
    "        cur_step (int): The current step.\n",
    "        writer: The TensorBoard writer.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "    test_recon_loss = 0\n",
    "    test_kl_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloader, desc='Testing'):\n",
    "            data = data.to(device)\n",
    "            data = data.view(data.size(0), -1)  # Flatten the data\n",
    "\n",
    "            output = model(data, compute_loss=True)  # Forward pass\n",
    "\n",
    "            test_loss += output.loss.item()\n",
    "            test_recon_loss += output.loss_recon.item()\n",
    "            test_kl_loss += output.loss_kl.item()\n",
    "\n",
    "    test_loss /= len(dataloader)\n",
    "    test_recon_loss /= len(dataloader)\n",
    "    test_kl_loss /= len(dataloader)\n",
    "    print(f'====> Test set loss: {test_loss:.4f} (BCE: {test_recon_loss:.4f}, KLD: {test_kl_loss:.4f})')\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.add_scalar('Loss/Test', test_loss, global_step=cur_step)\n",
    "        writer.add_scalar('Loss/Test/BCE', output.loss_recon.item(), global_step=cur_step)\n",
    "        writer.add_scalar('Loss/Test/KLD', output.loss_kl.item(), global_step=cur_step)\n",
    "\n",
    "        # Log reconstructions\n",
    "        # writer.add_images('Test/Reconstructions', output.x_recon.view(-1, 1, 28, 28), global_step=cur_step)\n",
    "        # writer.add_images('Test/Originals', data.view(-1, 1, 28, 28), global_step=cur_step)\n",
    "\n",
    "        # Log random samples from the latent space\n",
    "        z = torch.randn(16, latent_dim).to(device)\n",
    "        samples = model.decode(z)\n",
    "        # writer.add_images('Test/Samples', samples.view(-1, 1, 28, 28), global_step=cur_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/365 [00:00<00:06, 55.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 (N samples: 0), Loss: 3.3121 (Recon: 1.4142, KL: 1.8979) Grad: 1.7928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 126/365 [00:00<00:01, 155.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 (N samples: 12,800), Loss: 2.5398 (Recon: 1.2065, KL: 1.3333) Grad: 1.4889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 227/365 [00:01<00:00, 143.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 (N samples: 25,600), Loss: 1.8282 (Recon: 1.0219, KL: 0.8062) Grad: 1.2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 322/365 [00:02<00:00, 136.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 (N samples: 38,400), Loss: 1.3751 (Recon: 1.0189, KL: 0.3562) Grad: 0.8659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 138.28it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 241.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.3509 (BCE: 1.1564, KLD: 0.1945)\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 53/365 [00:00<00:02, 129.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 (N samples: 51,200), Loss: 1.0374 (Recon: 0.9006, KL: 0.1368) Grad: 0.5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 151/365 [00:01<00:01, 136.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 (N samples: 64,000), Loss: 1.2200 (Recon: 1.1725, KL: 0.0475) Grad: 0.3631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 252/365 [00:01<00:00, 127.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 (N samples: 76,800), Loss: 1.0369 (Recon: 1.0244, KL: 0.0125) Grad: 0.2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 352/365 [00:02<00:00, 134.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 700 (N samples: 89,600), Loss: 0.9562 (Recon: 0.9537, KL: 0.0025) Grad: 0.1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 131.15it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 258.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.0736 (BCE: 1.0714, KLD: 0.0021)\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 96/365 [00:00<00:01, 135.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800 (N samples: 102,400), Loss: 1.3259 (Recon: 1.3248, KL: 0.0012) Grad: 0.0740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 188/365 [00:01<00:01, 143.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 900 (N samples: 115,200), Loss: 0.7981 (Recon: 0.7980, KL: 0.0001) Grad: 0.0558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 293/365 [00:01<00:00, 167.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,000 (N samples: 128,000), Loss: 0.9220 (Recon: 0.9218, KL: 0.0002) Grad: 0.0472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 150.47it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 345.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.0296 (BCE: 1.0294, KLD: 0.0002)\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 13/365 [00:00<00:02, 129.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,100 (N samples: 140,800), Loss: 0.8240 (Recon: 0.8239, KL: 0.0001) Grad: 0.0556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 139/365 [00:00<00:01, 162.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,200 (N samples: 153,600), Loss: 0.9865 (Recon: 0.9864, KL: 0.0001) Grad: 0.0398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 233/365 [00:01<00:00, 175.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,300 (N samples: 166,400), Loss: 0.9169 (Recon: 0.9168, KL: 0.0001) Grad: 0.0336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 321/365 [00:02<00:00, 145.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,400 (N samples: 179,200), Loss: 0.8828 (Recon: 0.8826, KL: 0.0001) Grad: 0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 151.08it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 241.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.0060 (BCE: 1.0059, KLD: 0.0001)\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 63/365 [00:00<00:02, 134.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,500 (N samples: 192,000), Loss: 0.9706 (Recon: 0.9705, KL: 0.0001) Grad: 0.0265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 163/365 [00:01<00:01, 139.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,600 (N samples: 204,800), Loss: 0.8835 (Recon: 0.8835, KL: 0.0000) Grad: 0.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 262/365 [00:01<00:00, 159.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,700 (N samples: 217,600), Loss: 0.7215 (Recon: 0.7215, KL: 0.0000) Grad: 0.0350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 148.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,800 (N samples: 230,400), Loss: 0.9817 (Recon: 0.9817, KL: 0.0000) Grad: 0.0295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 346.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9919 (BCE: 0.9919, KLD: 0.0000)\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 98/365 [00:00<00:01, 182.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,900 (N samples: 243,200), Loss: 0.8650 (Recon: 0.8650, KL: 0.0000) Grad: 0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 213/365 [00:01<00:00, 185.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,000 (N samples: 256,000), Loss: 0.7310 (Recon: 0.7310, KL: 0.0000) Grad: 0.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 294/365 [00:01<00:00, 191.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,100 (N samples: 268,800), Loss: 0.9268 (Recon: 0.9267, KL: 0.0000) Grad: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 187.44it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 337.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9830 (BCE: 0.9830, KLD: 0.0000)\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 16/365 [00:00<00:02, 159.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,200 (N samples: 281,600), Loss: 1.3865 (Recon: 1.3864, KL: 0.0001) Grad: 0.0359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 143/365 [00:00<00:01, 154.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,300 (N samples: 294,400), Loss: 0.8005 (Recon: 0.8005, KL: 0.0000) Grad: 0.0231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 238/365 [00:01<00:00, 175.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,400 (N samples: 307,200), Loss: 1.0149 (Recon: 1.0149, KL: 0.0000) Grad: 0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 334/365 [00:02<00:00, 136.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,500 (N samples: 320,000), Loss: 2.3079 (Recon: 2.3079, KL: 0.0000) Grad: 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 149.57it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 311.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9771 (BCE: 0.9771, KLD: 0.0000)\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 68/365 [00:00<00:02, 124.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,600 (N samples: 332,800), Loss: 0.9106 (Recon: 0.9106, KL: 0.0000) Grad: 0.0151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 178/365 [00:01<00:01, 173.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,700 (N samples: 345,600), Loss: 0.7992 (Recon: 0.7992, KL: 0.0000) Grad: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 274/365 [00:01<00:00, 186.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,800 (N samples: 358,400), Loss: 0.8588 (Recon: 0.8588, KL: 0.0000) Grad: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 166.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,900 (N samples: 371,200), Loss: 1.2196 (Recon: 1.2196, KL: 0.0000) Grad: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 294.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9731 (BCE: 0.9731, KLD: 0.0000)\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 104/365 [00:00<00:01, 131.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,000 (N samples: 384,000), Loss: 0.9144 (Recon: 0.9144, KL: 0.0000) Grad: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 201/365 [00:01<00:01, 129.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,100 (N samples: 396,800), Loss: 0.8400 (Recon: 0.8400, KL: 0.0000) Grad: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 302/365 [00:02<00:00, 132.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,200 (N samples: 409,600), Loss: 0.8603 (Recon: 0.8603, KL: 0.0000) Grad: 0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 132.46it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 255.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9702 (BCE: 0.9702, KLD: 0.0000)\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 12/365 [00:00<00:02, 117.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,300 (N samples: 422,400), Loss: 1.3803 (Recon: 1.3803, KL: 0.0000) Grad: 0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 147/365 [00:01<00:01, 153.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,400 (N samples: 435,200), Loss: 0.9044 (Recon: 0.9044, KL: 0.0000) Grad: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 242/365 [00:01<00:00, 178.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,500 (N samples: 448,000), Loss: 3.4329 (Recon: 3.4329, KL: 0.0000) Grad: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 338/365 [00:02<00:00, 179.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,600 (N samples: 460,800), Loss: 0.8129 (Recon: 0.8129, KL: 0.0000) Grad: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 161.69it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 307.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9681 (BCE: 0.9681, KLD: 0.0000)\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 76/365 [00:00<00:01, 175.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,700 (N samples: 473,600), Loss: 0.8090 (Recon: 0.8090, KL: 0.0000) Grad: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 172/365 [00:00<00:01, 184.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,800 (N samples: 486,400), Loss: 1.1385 (Recon: 1.1385, KL: 0.0000) Grad: 0.0072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 288/365 [00:01<00:00, 188.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,900 (N samples: 499,200), Loss: 0.8531 (Recon: 0.8531, KL: 0.0000) Grad: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 183.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,000 (N samples: 512,000), Loss: 0.8311 (Recon: 0.8311, KL: 0.0000) Grad: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 320.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9666 (BCE: 0.9666, KLD: 0.0000)\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 116/365 [00:00<00:01, 175.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,100 (N samples: 524,800), Loss: 0.8197 (Recon: 0.8197, KL: 0.0000) Grad: 0.0081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 214/365 [00:01<00:00, 188.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,200 (N samples: 537,600), Loss: 0.7429 (Recon: 0.7429, KL: 0.0000) Grad: 0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 309/365 [00:01<00:00, 184.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,300 (N samples: 550,400), Loss: 0.8972 (Recon: 0.8972, KL: 0.0000) Grad: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 183.69it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 339.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9654 (BCE: 0.9654, KLD: 0.0000)\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 18/365 [00:00<00:01, 179.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,400 (N samples: 563,200), Loss: 6.2187 (Recon: 6.2187, KL: 0.0000) Grad: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 153/365 [00:00<00:01, 175.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,500 (N samples: 576,000), Loss: 0.9436 (Recon: 0.9436, KL: 0.0000) Grad: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 246/365 [00:01<00:00, 179.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,600 (N samples: 588,800), Loss: 0.8471 (Recon: 0.8471, KL: 0.0000) Grad: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 340/365 [00:01<00:00, 176.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,700 (N samples: 601,600), Loss: 0.8252 (Recon: 0.8252, KL: 0.0000) Grad: 0.0036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 178.13it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 347.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9644 (BCE: 0.9644, KLD: 0.0000)\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 90/365 [00:00<00:01, 175.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,800 (N samples: 614,400), Loss: 0.9457 (Recon: 0.9457, KL: 0.0000) Grad: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 185/365 [00:01<00:01, 172.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,900 (N samples: 627,200), Loss: 0.8273 (Recon: 0.8273, KL: 0.0000) Grad: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 278/365 [00:01<00:00, 175.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,000 (N samples: 640,000), Loss: 0.7348 (Recon: 0.7348, KL: 0.0000) Grad: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 176.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,100 (N samples: 652,800), Loss: 0.9156 (Recon: 0.9156, KL: 0.0000) Grad: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 325.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9637 (BCE: 0.9637, KLD: 0.0000)\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 117/365 [00:00<00:01, 183.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,200 (N samples: 665,600), Loss: 0.8986 (Recon: 0.8986, KL: 0.0000) Grad: 0.0034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 215/365 [00:01<00:00, 187.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,300 (N samples: 678,400), Loss: 0.8042 (Recon: 0.8042, KL: 0.0000) Grad: 0.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 310/365 [00:01<00:00, 180.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,400 (N samples: 691,200), Loss: 0.7556 (Recon: 0.7556, KL: 0.0000) Grad: 0.0037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 180.13it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 326.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9631 (BCE: 0.9631, KLD: 0.0000)\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 20/365 [00:00<00:01, 192.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,500 (N samples: 704,000), Loss: 0.7646 (Recon: 0.7646, KL: 0.0000) Grad: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 151/365 [00:00<00:01, 181.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,600 (N samples: 716,800), Loss: 0.8752 (Recon: 0.8752, KL: 0.0000) Grad: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 261/365 [00:01<00:00, 176.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,700 (N samples: 729,600), Loss: 0.8355 (Recon: 0.8355, KL: 0.0000) Grad: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 351/365 [00:01<00:00, 176.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,800 (N samples: 742,400), Loss: 0.7703 (Recon: 0.7703, KL: 0.0000) Grad: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 175.31it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 320.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9627 (BCE: 0.9627, KLD: 0.0000)\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 94/365 [00:00<00:01, 188.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5,900 (N samples: 755,200), Loss: 0.8692 (Recon: 0.8692, KL: 0.0000) Grad: 0.0040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 191/365 [00:01<00:00, 182.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,000 (N samples: 768,000), Loss: 1.0410 (Recon: 1.0410, KL: 0.0000) Grad: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 287/365 [00:01<00:00, 180.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,100 (N samples: 780,800), Loss: 0.8767 (Recon: 0.8767, KL: 0.0000) Grad: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 180.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,200 (N samples: 793,600), Loss: 0.9026 (Recon: 0.9026, KL: 0.0000) Grad: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 332.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9623 (BCE: 0.9623, KLD: 0.0000)\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 117/365 [00:00<00:01, 174.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,300 (N samples: 806,400), Loss: 0.7856 (Recon: 0.7856, KL: 0.0000) Grad: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 227/365 [00:01<00:00, 176.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,400 (N samples: 819,200), Loss: 0.9054 (Recon: 0.9054, KL: 0.0000) Grad: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 321/365 [00:01<00:00, 180.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,500 (N samples: 832,000), Loss: 0.9786 (Recon: 0.9786, KL: 0.0000) Grad: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 177.24it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 320.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9620 (BCE: 0.9620, KLD: 0.0000)\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 15/365 [00:00<00:02, 146.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,600 (N samples: 844,800), Loss: 0.8351 (Recon: 0.8351, KL: 0.0000) Grad: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 155/365 [00:00<00:01, 195.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,700 (N samples: 857,600), Loss: 0.8645 (Recon: 0.8645, KL: 0.0000) Grad: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 251/365 [00:01<00:00, 176.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,800 (N samples: 870,400), Loss: 0.7085 (Recon: 0.7085, KL: 0.0000) Grad: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 179.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6,900 (N samples: 883,200), Loss: 0.7932 (Recon: 0.7932, KL: 0.0000) Grad: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 342.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9617 (BCE: 0.9617, KLD: 0.0000)\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 94/365 [00:00<00:01, 182.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,000 (N samples: 896,000), Loss: 0.9745 (Recon: 0.9745, KL: 0.0000) Grad: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 187/365 [00:01<00:00, 181.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,100 (N samples: 908,800), Loss: 0.8706 (Recon: 0.8706, KL: 0.0000) Grad: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 301/365 [00:01<00:00, 186.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,200 (N samples: 921,600), Loss: 0.8805 (Recon: 0.8805, KL: 0.0000) Grad: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 180.84it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 338.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9615 (BCE: 0.9615, KLD: 0.0000)\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 20/365 [00:00<00:01, 194.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,300 (N samples: 934,400), Loss: 1.3184 (Recon: 1.3184, KL: 0.0000) Grad: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 136/365 [00:00<00:01, 185.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,400 (N samples: 947,200), Loss: 0.8340 (Recon: 0.8340, KL: 0.0000) Grad: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 232/365 [00:01<00:00, 185.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,500 (N samples: 960,000), Loss: 0.8809 (Recon: 0.8808, KL: 0.0000) Grad: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 330/365 [00:01<00:00, 184.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,600 (N samples: 972,800), Loss: 0.8174 (Recon: 0.8174, KL: 0.0000) Grad: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 182.43it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 344.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9614 (BCE: 0.9614, KLD: 0.0000)\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 20/365 [00:00<00:01, 193.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,700 (N samples: 985,600), Loss: 0.8609 (Recon: 0.8609, KL: 0.0000) Grad: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 161/365 [00:00<00:01, 197.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,800 (N samples: 998,400), Loss: 0.8495 (Recon: 0.8495, KL: 0.0000) Grad: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 259/365 [00:01<00:00, 189.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7,900 (N samples: 1,011,200), Loss: 1.0256 (Recon: 1.0256, KL: 0.0000) Grad: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 186.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,000 (N samples: 1,024,000), Loss: 0.9268 (Recon: 0.9268, KL: 0.0000) Grad: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 340.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9612 (BCE: 0.9612, KLD: 0.0000)\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 99/365 [00:00<00:01, 192.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,100 (N samples: 1,036,800), Loss: 0.9963 (Recon: 0.9963, KL: 0.0000) Grad: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 201/365 [00:01<00:00, 195.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,200 (N samples: 1,049,600), Loss: 0.8967 (Recon: 0.8967, KL: 0.0000) Grad: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 303/365 [00:01<00:00, 189.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,300 (N samples: 1,062,400), Loss: 0.9171 (Recon: 0.9171, KL: 0.0000) Grad: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 188.36it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 329.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9611 (BCE: 0.9611, KLD: 0.0000)\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 20/365 [00:00<00:01, 194.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,400 (N samples: 1,075,200), Loss: 0.8663 (Recon: 0.8663, KL: 0.0000) Grad: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 136/365 [00:00<00:01, 184.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,500 (N samples: 1,088,000), Loss: 0.8051 (Recon: 0.8051, KL: 0.0000) Grad: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 231/365 [00:01<00:00, 184.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,600 (N samples: 1,100,800), Loss: 0.7947 (Recon: 0.7947, KL: 0.0000) Grad: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 331/365 [00:01<00:00, 186.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,700 (N samples: 1,113,600), Loss: 1.0355 (Recon: 1.0355, KL: 0.0000) Grad: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 183.49it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 325.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9610 (BCE: 0.9610, KLD: 0.0000)\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 79/365 [00:00<00:01, 190.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,800 (N samples: 1,126,400), Loss: 0.9641 (Recon: 0.9641, KL: 0.0000) Grad: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 175/365 [00:00<00:01, 184.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8,900 (N samples: 1,139,200), Loss: 0.8953 (Recon: 0.8953, KL: 0.0000) Grad: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 271/365 [00:01<00:00, 185.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,000 (N samples: 1,152,000), Loss: 0.8380 (Recon: 0.8380, KL: 0.0000) Grad: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 180.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,100 (N samples: 1,164,800), Loss: 0.7847 (Recon: 0.7847, KL: 0.0000) Grad: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 352.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9609 (BCE: 0.9609, KLD: 0.0000)\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 98/365 [00:00<00:01, 194.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,200 (N samples: 1,177,600), Loss: 0.8582 (Recon: 0.8582, KL: 0.0000) Grad: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 195/365 [00:01<00:00, 179.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,300 (N samples: 1,190,400), Loss: 0.8157 (Recon: 0.8157, KL: 0.0000) Grad: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 312/365 [00:01<00:00, 180.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,400 (N samples: 1,203,200), Loss: 0.7863 (Recon: 0.7863, KL: 0.0000) Grad: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 181.00it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 345.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9609 (BCE: 0.9609, KLD: 0.0000)\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 18/365 [00:00<00:01, 177.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,500 (N samples: 1,216,000), Loss: 0.8432 (Recon: 0.8432, KL: 0.0000) Grad: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 138/365 [00:00<00:01, 195.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,600 (N samples: 1,228,800), Loss: 0.8616 (Recon: 0.8616, KL: 0.0000) Grad: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 239/365 [00:01<00:00, 190.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,700 (N samples: 1,241,600), Loss: 1.0973 (Recon: 1.0973, KL: 0.0000) Grad: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 338/365 [00:01<00:00, 188.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,800 (N samples: 1,254,400), Loss: 1.1154 (Recon: 1.1154, KL: 0.0000) Grad: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 189.66it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 375.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9608 (BCE: 0.9608, KLD: 0.0000)\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 78/365 [00:00<00:01, 188.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9,900 (N samples: 1,267,200), Loss: 0.8559 (Recon: 0.8559, KL: 0.0000) Grad: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 172/365 [00:00<00:01, 179.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,000 (N samples: 1,280,000), Loss: 1.1680 (Recon: 1.1680, KL: 0.0000) Grad: 0.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 270/365 [00:01<00:00, 192.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,100 (N samples: 1,292,800), Loss: 0.9232 (Recon: 0.9232, KL: 0.0000) Grad: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 187.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,200 (N samples: 1,305,600), Loss: 1.3018 (Recon: 1.3018, KL: 0.0000) Grad: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 344.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9608 (BCE: 0.9608, KLD: 0.0000)\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 101/365 [00:00<00:01, 188.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,300 (N samples: 1,318,400), Loss: 0.9145 (Recon: 0.9145, KL: 0.0000) Grad: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 200/365 [00:01<00:00, 189.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,400 (N samples: 1,331,200), Loss: 0.9838 (Recon: 0.9838, KL: 0.0000) Grad: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 299/365 [00:01<00:00, 186.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,500 (N samples: 1,344,000), Loss: 1.0064 (Recon: 1.0064, KL: 0.0000) Grad: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 188.73it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 337.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9607 (BCE: 0.9607, KLD: 0.0000)\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 17/365 [00:00<00:02, 169.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,600 (N samples: 1,356,800), Loss: 0.7661 (Recon: 0.7661, KL: 0.0000) Grad: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 151/365 [00:00<00:01, 177.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,700 (N samples: 1,369,600), Loss: 0.8063 (Recon: 0.8063, KL: 0.0000) Grad: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 250/365 [00:01<00:00, 186.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,800 (N samples: 1,382,400), Loss: 0.9141 (Recon: 0.9141, KL: 0.0000) Grad: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 347/365 [00:01<00:00, 184.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10,900 (N samples: 1,395,200), Loss: 0.9996 (Recon: 0.9996, KL: 0.0000) Grad: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 183.01it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 345.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9607 (BCE: 0.9607, KLD: 0.0000)\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 80/365 [00:00<00:01, 192.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,000 (N samples: 1,408,000), Loss: 0.9380 (Recon: 0.9380, KL: 0.0000) Grad: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 179/365 [00:00<00:00, 192.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,100 (N samples: 1,420,800), Loss: 0.8634 (Recon: 0.8634, KL: 0.0000) Grad: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 280/365 [00:01<00:00, 191.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,200 (N samples: 1,433,600), Loss: 0.8431 (Recon: 0.8431, KL: 0.0000) Grad: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 189.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,300 (N samples: 1,446,400), Loss: 0.9782 (Recon: 0.9782, KL: 0.0000) Grad: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 351.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9606 (BCE: 0.9606, KLD: 0.0000)\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 122/365 [00:00<00:01, 198.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,400 (N samples: 1,459,200), Loss: 0.7541 (Recon: 0.7541, KL: 0.0000) Grad: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 225/365 [00:01<00:00, 193.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,500 (N samples: 1,472,000), Loss: 0.9402 (Recon: 0.9401, KL: 0.0000) Grad: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 323/365 [00:01<00:00, 185.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,600 (N samples: 1,484,800), Loss: 0.9202 (Recon: 0.9202, KL: 0.0000) Grad: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 190.04it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 329.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9606 (BCE: 0.9606, KLD: 0.0000)\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 20/365 [00:00<00:01, 196.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,700 (N samples: 1,497,600), Loss: 0.7975 (Recon: 0.7975, KL: 0.0000) Grad: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 157/365 [00:00<00:01, 189.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,800 (N samples: 1,510,400), Loss: 0.8774 (Recon: 0.8774, KL: 0.0000) Grad: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 257/365 [00:01<00:00, 194.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11,900 (N samples: 1,523,200), Loss: 0.8504 (Recon: 0.8504, KL: 0.0000) Grad: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 359/365 [00:01<00:00, 198.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,000 (N samples: 1,536,000), Loss: 0.8046 (Recon: 0.8046, KL: 0.0000) Grad: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 190.70it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 331.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9606 (BCE: 0.9606, KLD: 0.0000)\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 88/365 [00:00<00:01, 173.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,100 (N samples: 1,548,800), Loss: 0.7235 (Recon: 0.7235, KL: 0.0000) Grad: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 185/365 [00:01<00:00, 186.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,200 (N samples: 1,561,600), Loss: 0.8475 (Recon: 0.8475, KL: 0.0000) Grad: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 282/365 [00:01<00:00, 188.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,300 (N samples: 1,574,400), Loss: 0.8308 (Recon: 0.8308, KL: 0.0000) Grad: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 181.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,400 (N samples: 1,587,200), Loss: 0.7647 (Recon: 0.7647, KL: 0.0000) Grad: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 357.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9606 (BCE: 0.9606, KLD: 0.0000)\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 115/365 [00:00<00:01, 187.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,500 (N samples: 1,600,000), Loss: 1.0468 (Recon: 1.0468, KL: 0.0000) Grad: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 214/365 [00:01<00:00, 188.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,600 (N samples: 1,612,800), Loss: 0.8699 (Recon: 0.8699, KL: 0.0000) Grad: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 313/365 [00:01<00:00, 192.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,700 (N samples: 1,625,600), Loss: 0.7809 (Recon: 0.7809, KL: 0.0000) Grad: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 186.34it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 340.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9606 (BCE: 0.9606, KLD: 0.0000)\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 18/365 [00:00<00:01, 179.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,800 (N samples: 1,638,400), Loss: 1.0590 (Recon: 1.0590, KL: 0.0000) Grad: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 159/365 [00:00<00:01, 196.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12,900 (N samples: 1,651,200), Loss: 0.7440 (Recon: 0.7440, KL: 0.0000) Grad: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 260/365 [00:01<00:00, 191.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,000 (N samples: 1,664,000), Loss: 0.7921 (Recon: 0.7921, KL: 0.0000) Grad: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 362/365 [00:01<00:00, 190.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,100 (N samples: 1,676,800), Loss: 0.7459 (Recon: 0.7459, KL: 0.0000) Grad: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 190.30it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 339.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9606 (BCE: 0.9605, KLD: 0.0000)\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 77/365 [00:00<00:01, 178.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,200 (N samples: 1,689,600), Loss: 0.9124 (Recon: 0.9124, KL: 0.0000) Grad: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 193/365 [00:01<00:00, 185.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,300 (N samples: 1,702,400), Loss: 0.9696 (Recon: 0.9696, KL: 0.0000) Grad: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 290/365 [00:01<00:00, 185.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,400 (N samples: 1,715,200), Loss: 0.8229 (Recon: 0.8229, KL: 0.0000) Grad: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 181.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,500 (N samples: 1,728,000), Loss: 0.9616 (Recon: 0.9616, KL: 0.0000) Grad: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 350.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9605 (BCE: 0.9605, KLD: 0.0000)\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 120/365 [00:00<00:01, 186.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,600 (N samples: 1,740,800), Loss: 0.8587 (Recon: 0.8586, KL: 0.0000) Grad: 0.0056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 214/365 [00:01<00:00, 176.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,700 (N samples: 1,753,600), Loss: 0.9850 (Recon: 0.9850, KL: 0.0000) Grad: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 315/365 [00:01<00:00, 189.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,800 (N samples: 1,766,400), Loss: 0.7144 (Recon: 0.7144, KL: 0.0000) Grad: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 183.11it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 367.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9605 (BCE: 0.9605, KLD: 0.0000)\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 18/365 [00:00<00:01, 175.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13,900 (N samples: 1,779,200), Loss: 0.8349 (Recon: 0.8349, KL: 0.0000) Grad: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 156/365 [00:00<00:01, 186.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,000 (N samples: 1,792,000), Loss: 11.6820 (Recon: 11.6820, KL: 0.0001) Grad: 0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 249/365 [00:01<00:00, 177.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,100 (N samples: 1,804,800), Loss: 0.7350 (Recon: 0.7350, KL: 0.0000) Grad: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 185.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,200 (N samples: 1,817,600), Loss: 0.7379 (Recon: 0.7379, KL: 0.0000) Grad: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 353.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9605 (BCE: 0.9605, KLD: 0.0000)\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 98/365 [00:00<00:01, 192.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,300 (N samples: 1,830,400), Loss: 0.9324 (Recon: 0.9324, KL: 0.0000) Grad: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 201/365 [00:01<00:00, 190.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,400 (N samples: 1,843,200), Loss: 0.8012 (Recon: 0.8012, KL: 0.0000) Grad: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 301/365 [00:01<00:00, 188.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,500 (N samples: 1,856,000), Loss: 0.9761 (Recon: 0.9761, KL: 0.0000) Grad: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 187.88it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 353.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9605 (BCE: 0.9605, KLD: 0.0000)\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 17/365 [00:00<00:02, 169.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,600 (N samples: 1,868,800), Loss: 0.8323 (Recon: 0.8323, KL: 0.0000) Grad: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 132/365 [00:00<00:01, 181.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,700 (N samples: 1,881,600), Loss: 0.8954 (Recon: 0.8954, KL: 0.0000) Grad: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 229/365 [00:01<00:00, 186.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,800 (N samples: 1,894,400), Loss: 0.9439 (Recon: 0.9439, KL: 0.0000) Grad: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 325/365 [00:01<00:00, 182.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14,900 (N samples: 1,907,200), Loss: 0.8420 (Recon: 0.8420, KL: 0.0000) Grad: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 183.39it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 328.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9605 (BCE: 0.9605, KLD: 0.0000)\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 71/365 [00:00<00:01, 176.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,000 (N samples: 1,920,000), Loss: 0.8475 (Recon: 0.8475, KL: 0.0000) Grad: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 168/365 [00:00<00:01, 183.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,100 (N samples: 1,932,800), Loss: 0.9155 (Recon: 0.9155, KL: 0.0000) Grad: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 263/365 [00:01<00:00, 184.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,200 (N samples: 1,945,600), Loss: 0.8719 (Recon: 0.8719, KL: 0.0000) Grad: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 181.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,300 (N samples: 1,958,400), Loss: 0.7661 (Recon: 0.7661, KL: 0.0000) Grad: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 314.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9605 (BCE: 0.9605, KLD: 0.0000)\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 98/365 [00:00<00:01, 191.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,400 (N samples: 1,971,200), Loss: 0.7737 (Recon: 0.7737, KL: 0.0000) Grad: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 197/365 [00:01<00:00, 190.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,500 (N samples: 1,984,000), Loss: 0.8173 (Recon: 0.8173, KL: 0.0000) Grad: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 300/365 [00:01<00:00, 190.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,600 (N samples: 1,996,800), Loss: 0.7600 (Recon: 0.7600, KL: 0.0000) Grad: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 187.80it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 346.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9605 (BCE: 0.9605, KLD: 0.0000)\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 17/365 [00:00<00:02, 167.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,700 (N samples: 2,009,600), Loss: 0.8037 (Recon: 0.8037, KL: 0.0000) Grad: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 129/365 [00:00<00:01, 182.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,800 (N samples: 2,022,400), Loss: 1.0728 (Recon: 1.0728, KL: 0.0000) Grad: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 225/365 [00:01<00:00, 182.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15,900 (N samples: 2,035,200), Loss: 0.8730 (Recon: 0.8730, KL: 0.0000) Grad: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 340/365 [00:01<00:00, 183.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,000 (N samples: 2,048,000), Loss: 0.8198 (Recon: 0.8198, KL: 0.0000) Grad: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 178.52it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 342.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9605 (BCE: 0.9605, KLD: 0.0000)\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 72/365 [00:00<00:01, 170.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,100 (N samples: 2,060,800), Loss: 0.9855 (Recon: 0.9855, KL: 0.0000) Grad: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 168/365 [00:00<00:01, 174.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,200 (N samples: 2,073,600), Loss: 0.9309 (Recon: 0.9309, KL: 0.0000) Grad: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 268/365 [00:01<00:00, 188.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,300 (N samples: 2,086,400), Loss: 0.7462 (Recon: 0.7462, KL: 0.0000) Grad: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 180.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,400 (N samples: 2,099,200), Loss: 0.7474 (Recon: 0.7474, KL: 0.0000) Grad: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 324.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9605 (BCE: 0.9605, KLD: 0.0000)\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 101/365 [00:00<00:01, 198.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,500 (N samples: 2,112,000), Loss: 0.8208 (Recon: 0.8208, KL: 0.0000) Grad: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 200/365 [00:01<00:00, 189.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,600 (N samples: 2,124,800), Loss: 0.9499 (Recon: 0.9499, KL: 0.0000) Grad: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 302/365 [00:01<00:00, 194.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,700 (N samples: 2,137,600), Loss: 0.8079 (Recon: 0.8079, KL: 0.0000) Grad: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 193.04it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 353.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9605 (BCE: 0.9605, KLD: 0.0000)\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 19/365 [00:00<00:01, 186.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,800 (N samples: 2,150,400), Loss: 0.7898 (Recon: 0.7898, KL: 0.0000) Grad: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 140/365 [00:00<00:01, 191.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16,900 (N samples: 2,163,200), Loss: 0.8499 (Recon: 0.8499, KL: 0.0000) Grad: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 245/365 [00:01<00:00, 201.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,000 (N samples: 2,176,000), Loss: 0.9151 (Recon: 0.9151, KL: 0.0000) Grad: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 326/365 [00:01<00:00, 177.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,100 (N samples: 2,188,800), Loss: 0.8720 (Recon: 0.8720, KL: 0.0000) Grad: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:01<00:00, 188.75it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 329.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9605 (BCE: 0.9605, KLD: 0.0000)\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 70/365 [00:00<00:01, 175.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,200 (N samples: 2,201,600), Loss: 0.8011 (Recon: 0.8011, KL: 0.0000) Grad: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 163/365 [00:00<00:01, 178.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,300 (N samples: 2,214,400), Loss: 0.8299 (Recon: 0.8299, KL: 0.0000) Grad: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 281/365 [00:01<00:00, 188.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,400 (N samples: 2,227,200), Loss: 0.8038 (Recon: 0.8038, KL: 0.0000) Grad: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 178.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,500 (N samples: 2,240,000), Loss: 0.8376 (Recon: 0.8376, KL: 0.0000) Grad: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 329.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9605 (BCE: 0.9605, KLD: 0.0000)\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 114/365 [00:00<00:01, 182.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,600 (N samples: 2,252,800), Loss: 0.7289 (Recon: 0.7289, KL: 0.0000) Grad: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 207/365 [00:01<00:00, 179.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,700 (N samples: 2,265,600), Loss: 0.8961 (Recon: 0.8961, KL: 0.0000) Grad: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 303/365 [00:01<00:00, 183.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,800 (N samples: 2,278,400), Loss: 0.8090 (Recon: 0.8090, KL: 0.0000) Grad: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 178.16it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 322.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9605 (BCE: 0.9605, KLD: 0.0000)\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 17/365 [00:00<00:02, 169.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17,900 (N samples: 2,291,200), Loss: 0.8164 (Recon: 0.8164, KL: 0.0000) Grad: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 145/365 [00:00<00:01, 177.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18,000 (N samples: 2,304,000), Loss: 0.8797 (Recon: 0.8797, KL: 0.0000) Grad: 0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 242/365 [00:01<00:00, 184.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18,100 (N samples: 2,316,800), Loss: 0.9405 (Recon: 0.9405, KL: 0.0000) Grad: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 353/365 [00:01<00:00, 178.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18,200 (N samples: 2,329,600), Loss: 1.2128 (Recon: 1.2128, KL: 0.0000) Grad: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [00:02<00:00, 176.14it/s]\n",
      "Testing: 100%|██████████| 92/92 [00:00<00:00, 341.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 0.9605 (BCE: 0.9605, KLD: 0.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prev_updates = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    prev_updates = train(model, train_loader, optimizer, prev_updates, writer=writer)\n",
    "    test(model, test_loader, prev_updates, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2210, -1.0086, -0.6880, -0.2019, -0.0487,  0.3439,  0.0515]])\n",
      "tensor([[0.0087, 0.0063, 0.0079, 0.0100, 0.0085, 0.0087, 0.0085]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sample_ = train_loader.dataset[100].unsqueeze(0)\n",
    "result_ = model(sample_)\n",
    "\n",
    "print(sample_)\n",
    "print(result_.x_recon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
